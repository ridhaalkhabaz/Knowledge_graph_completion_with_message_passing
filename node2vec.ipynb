{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d302afe-37e1-4abb-93a2-79cabd3f7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx \n",
    "import scipy.sparse as ssp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.datasets import FB15k_237\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "from torch_geometric.datasets import RelLinkPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63167777-af08-4812-8ccd-1393571a92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful function \n",
    "def mask_test_edges(adj, test_frac=.1, val_frac=.05, prevent_disconnect=True, verbose=False):\n",
    "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
    "\n",
    "    if verbose == True:\n",
    "        print('preprocessing...')\n",
    "\n",
    "    # Remove diagonal elements\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "    # Check that diag is zero:\n",
    "    assert np.diag(adj.todense()).sum() == 0\n",
    "\n",
    "    g = nx.from_scipy_sparse_matrix(adj)\n",
    "    orig_num_cc = nx.number_connected_components(g)\n",
    "\n",
    "    adj_triu = sp.triu(adj) # upper triangular portion of adj matrix\n",
    "    adj_tuple = sparse_to_tuple(adj_triu) # (coords, values, shape), edges only 1 way\n",
    "    edges = adj_tuple[0] # all edges, listed only once (not 2 ways)\n",
    "    # edges_all = sparse_to_tuple(adj)[0] # ALL edges (includes both ways)\n",
    "    num_test = int(np.floor(edges.shape[0] * test_frac)) # controls how large the test set should be\n",
    "    num_val = int(np.floor(edges.shape[0] * val_frac)) # controls how alrge the validation set should be\n",
    "\n",
    "    # Store edges in list of ordered tuples (node1, node2) where node1 < node2\n",
    "    edge_tuples = [(min(edge[0], edge[1]), max(edge[0], edge[1])) for edge in edges]\n",
    "    all_edge_tuples = set(edge_tuples)\n",
    "    train_edges = set(edge_tuples) # initialize train_edges to have all edges\n",
    "    test_edges = set()\n",
    "    val_edges = set()\n",
    "\n",
    "  \n",
    "\n",
    "    # Iterate over shuffled edges, add to train/val sets\n",
    "    np.random.shuffle(edge_tuples)\n",
    "    for edge in edge_tuples:\n",
    "        # print edge\n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "\n",
    "        # If removing edge would disconnect a connected component, backtrack and move on\n",
    "        g.remove_edge(node1, node2)\n",
    "        if prevent_disconnect == True:\n",
    "            if nx.number_connected_components(g) > orig_num_cc:\n",
    "                g.add_edge(node1, node2)\n",
    "                continue\n",
    "\n",
    "        # Fill test_edges first\n",
    "        if len(test_edges) < num_test:\n",
    "            test_edges.add(edge)\n",
    "            train_edges.remove(edge)\n",
    "\n",
    "        # Then, fill val_edges\n",
    "        elif len(val_edges) < num_val:\n",
    "            val_edges.add(edge)\n",
    "            train_edges.remove(edge)\n",
    "\n",
    "        # Both edge lists full --> break loop\n",
    "        elif len(test_edges) == num_test and len(val_edges) == num_val:\n",
    "            break\n",
    "\n",
    "    if (len(val_edges) < num_val or len(test_edges) < num_test):\n",
    "        print(\"WARNING: not enough removable edges to perform full train-test split!\")\n",
    "        print(\"Num. (test, val) edges requested: (\", num_test, \", \", num_val, \")\")\n",
    "        print(\"Num. (test, val) edges returned: (\", len(test_edges), \", \", len(val_edges), \")\")\n",
    "\n",
    "    if prevent_disconnect == True:\n",
    "        assert nx.number_connected_components(g) == orig_num_cc\n",
    "\n",
    " \n",
    "\n",
    "    test_edges_false = set()\n",
    "    while len(test_edges_false) < num_test:\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (min(idx_i, idx_j), max(idx_i, idx_j))\n",
    "\n",
    "        # Make sure false_edge not an actual edge, and not a repeat\n",
    "        if false_edge in all_edge_tuples:\n",
    "            continue\n",
    "        if false_edge in test_edges_false:\n",
    "            continue\n",
    "\n",
    "        test_edges_false.add(false_edge)\n",
    "\n",
    "\n",
    "    val_edges_false = set()\n",
    "    while len(val_edges_false) < num_val:\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (min(idx_i, idx_j), max(idx_i, idx_j))\n",
    "\n",
    "        # Make sure false_edge in not an actual edge, not in test_edges_false, not a repeat\n",
    "        if false_edge in all_edge_tuples or \\\n",
    "            false_edge in test_edges_false or \\\n",
    "            false_edge in val_edges_false:\n",
    "            continue\n",
    "            \n",
    "        val_edges_false.add(false_edge)\n",
    "\n",
    "    \n",
    "\n",
    "    train_edges_false = set()\n",
    "    while len(train_edges_false) < len(train_edges):\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (min(idx_i, idx_j), max(idx_i, idx_j))\n",
    "\n",
    "        # Make sure false_edge in not an actual edge, not in test_edges_false, \n",
    "            # not in val_edges_false, not a repeat\n",
    "        if false_edge in all_edge_tuples or \\\n",
    "            false_edge in test_edges_false or \\\n",
    "            false_edge in val_edges_false or \\\n",
    "            false_edge in train_edges_false:\n",
    "            continue\n",
    "\n",
    "        train_edges_false.add(false_edge)\n",
    "\n",
    "  \n",
    "\n",
    "    # assert: false_edges are actually false (not in all_edge_tuples)\n",
    "    assert test_edges_false.isdisjoint(all_edge_tuples)\n",
    "    assert val_edges_false.isdisjoint(all_edge_tuples)\n",
    "    assert train_edges_false.isdisjoint(all_edge_tuples)\n",
    "\n",
    "    # assert: test, val, train false edges disjoint\n",
    "    assert test_edges_false.isdisjoint(val_edges_false)\n",
    "    assert test_edges_false.isdisjoint(train_edges_false)\n",
    "    assert val_edges_false.isdisjoint(train_edges_false)\n",
    "\n",
    "    # assert: test, val, train positive edges disjoint\n",
    "    assert val_edges.isdisjoint(train_edges)\n",
    "    assert test_edges.isdisjoint(train_edges)\n",
    "    assert val_edges.isdisjoint(test_edges)\n",
    "\n",
    "   \n",
    "\n",
    "    # Re-build adj matrix using remaining graph\n",
    "    adj_train = nx.adjacency_matrix(g)\n",
    "\n",
    "    # Convert edge-lists to numpy arrays\n",
    "    train_edges = np.array([list(edge_tuple) for edge_tuple in train_edges])\n",
    "    train_edges_false = np.array([list(edge_tuple) for edge_tuple in train_edges_false])\n",
    "    val_edges = np.array([list(edge_tuple) for edge_tuple in val_edges])\n",
    "    val_edges_false = np.array([list(edge_tuple) for edge_tuple in val_edges_false])\n",
    "    test_edges = np.array([list(edge_tuple) for edge_tuple in test_edges])\n",
    "    test_edges_false = np.array([list(edge_tuple) for edge_tuple in test_edges_false])\n",
    "\n",
    "  \n",
    "\n",
    "    # NOTE: these edge lists only contain single direction of edge!\n",
    "    return adj_train, train_edges, train_edges_false, \\\n",
    "        val_edges, val_edges_false, test_edges, test_edges_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f536dc69-bb8b-4b58-9ddd-0abb52652af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/train.txt\n",
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/valid.txt\n",
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/test.txt\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = FB15k_237('./data')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5825c5c7-d7c8-4601-8518-7ecd690925b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/entities.dict\n",
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/relations.dict\n",
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/test.txt\n",
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/train.txt\n",
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/valid.txt\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "daset = RelLinkPredDataset('tmp', 'FB15k-237')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e101d178-ec22-4cb6-b001-5106b1c83547",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = daset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c0a9377-7c4d-455d-ad43-24756708fda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 544230], num_nodes=14541, edge_type=[544230], train_edge_index=[2, 272115], train_edge_type=[272115], valid_edge_index=[2, 17535], valid_edge_type=[17535], test_edge_index=[2, 20466], test_edge_type=[20466])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a84e25-08ab-4da3-8144-7842473753be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 272115], edge_type=[272115], num_nodes=14541)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d7e1036-613e-4ec2-8f4b-e89ef6448cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 17535], edge_type=[17535], num_nodes=14541)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = FB15k_237('./data', split='val')\n",
    "h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbef65f8-9322-478d-807c-5598aadd2b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 20466], edge_type=[20466], num_nodes=14541)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = FB15k_237('./data', split='test')\n",
    "h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638f40a-f2fb-42db-9171-29a4c304a330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
